{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import copy\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "                    #####################################################\n",
    "                    #                Auxiliary Functions                #\n",
    "                    #####################################################\n",
    "\n",
    "def is_symmetric(poly):         # Check if polynomial is symmetric in q and t\n",
    "    R = FractionField(QQ['q','t','x'])  # type: ignore\n",
    "    q,t,x = R.gens()\n",
    "    poly1 = R(poly)     # Casting in new ring\n",
    "    poly2 = poly1\n",
    "    poly2(q=x)\n",
    "    poly2(t=q)\n",
    "    poly2(x=t)\n",
    "    return (poly == poly2)\n",
    "\n",
    "def is_increasing_list(lst):\n",
    "    r\"\"\"\n",
    "        Checks if a list is weakly increasing.\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    check = True\n",
    "    while i < len(lst)-1 and check:\n",
    "        check = (lst[i]<=lst[i+1])\n",
    "        i += 1\n",
    "    return check\n",
    "\n",
    "\n",
    "                    #####################################################\n",
    "                    #           Sorted Sandpile Configuration           #\n",
    "                    #####################################################\n",
    "\n",
    "\n",
    "class SandpileSortConfig():\n",
    "\n",
    "    def __init__(self, sandp, conf, permut, sort = True, verts = []):      ## Defines the class SandpileSortConfig\n",
    "        r\"\"\"\n",
    "            Definition of the class SandpileSortConfig.\n",
    "            \n",
    "            The arguments given are a sandpile and a partition of the vertex set (without sink).\n",
    "        \"\"\"\n",
    "\n",
    "        ### TODO: check if the arguments given correspond to a good SandpileSortConfig\n",
    "\n",
    "        ### Handle the type of configuration given\n",
    "        if isinstance(conf, SandpileConfig):  #type: ignore\n",
    "            config = deepcopy({v:conf[v] for v in sandp.nonsink_vertices()})  #type: ignore\n",
    "        elif isinstance(conf, list):\n",
    "            vert = sandp.nonsink_vertices()\n",
    "            config = deepcopy({vert[i]:conf[i] for i in range(len(vert))})    #type: ignore\n",
    "        elif isinstance(conf, dict):\n",
    "            config = deepcopy(conf)                                           #type: ignore\n",
    "        else:\n",
    "            print(type(conf))\n",
    "            raise TypeError\n",
    "\n",
    "        self.sandpile_struct = sandp                                          # Define the sandpile_struct as sandp\n",
    "        self.perm_group = permut                                              # Define the permutation group on the sandpile\n",
    "        if verts == []:                                                       # Define the nonsink vertex set\n",
    "            self.vertices = sandp.nonsink_vertices()\n",
    "        else:\n",
    "            self.vertices = verts\n",
    "        self.sink = self.sandpile_struct.sink()                               # Define the sink vertex (efficiency!)\n",
    "\n",
    "        if sort:\n",
    "            # Reorder the configuration based on the permutation group\n",
    "            result = []\n",
    "            pos = {}\n",
    "            index = 0\n",
    "            for part in self.perm_group:\n",
    "                for i in part:\n",
    "                    pos.update({i:index})\n",
    "                    index += 1\n",
    "                part_conf = [config[i] for i in part]     # Get the partial configuration associated with an orbit\n",
    "                part_conf.sort()                          # Sort it\n",
    "                result = result + part_conf               # Modify the configuration\n",
    "            sort_conf = {i:result[pos[i]] for i in self.vertices}\n",
    "        else:\n",
    "            sort_conf = config\n",
    "\n",
    "        self.sandpile_config = SandpileConfig(sandp, sort_conf) # type: ignore  # Define the configuration for the sorted sandpile\n",
    "        \n",
    "\n",
    "    def __repr__(self):                             ## Returns a description of the class Sandpile2\n",
    "        return \"A sorted configuration for a sandpile with vertices {} and sink {}\".format(self.sandpile_struct.vertices(), self.sink)\n",
    "    \n",
    "\n",
    "    def sandpile_struct(self):\n",
    "        r\"\"\"\n",
    "            Returns the underlying sandpile structure.\n",
    "        \"\"\"\n",
    "        return self.sandpile_config.sandpile()\n",
    "\n",
    "    \n",
    "    def sort(self, change = True):\n",
    "        r\"\"\"\n",
    "            Rearrange the configuration values by increasing order on each orbit.\n",
    "\n",
    "            If change is True, it modifies the configuration, if it is False, it just returns the sorted one.\n",
    "        \"\"\"\n",
    "        result = []\n",
    "        pos = {}\n",
    "        index = 0\n",
    "\n",
    "        for part in self.perm_group:\n",
    "            for i in part:\n",
    "                pos.update({i:index})\n",
    "                index += 1\n",
    "            part_conf = [self.sandpile_config[i] for i in part]     # Get the partial configuration associated with an orbit\n",
    "            part_conf.sort()                          # Sort it\n",
    "            result = result + part_conf               # Modify the configuration\n",
    "        sort_conf = {i:result[pos[i]] for i in self.vertices}\n",
    "        if change:\n",
    "            self.sandpile_config = SandpileConfig(self.sandpile_struct, sort_conf) # type: ignore\n",
    "        return sort_conf\n",
    "    \n",
    "\n",
    "    def __deepcopy__(self, memo):\n",
    "        r\"\"\"\n",
    "            Overrides the deepcopy method for dict.\n",
    "        \"\"\"\n",
    "        c = SandpileSortConfig(self.sandpile_struct, dict(self.sandpile_config), self.perm_group)\n",
    "        c.sandpile_config.__dict__.update(self.sandpile_config.__dict__)\n",
    "        return c\n",
    "\n",
    "\n",
    "    def __eq__(self, other):                        ## Compares two sorted configurations to see if they are equivalent under the permutation group\n",
    "        r\"\"\"\n",
    "            Checks if the two sorded configurations are the same or not.\n",
    "        \"\"\"\n",
    "        return self.sandpile_config == other.sandpile_config\n",
    "\n",
    "    \n",
    "    def is_recurrent(self):                         ## Check if the configuration is recurrent\n",
    "        r\"\"\"\n",
    "            Check if the configuration is recurrent.\n",
    "            \n",
    "            This function just calls the function is_recurrent() from the class SandpileConfig. \n",
    "        \"\"\"\n",
    "        return self.sandpile_config.is_recurrent()\n",
    "    \n",
    "\n",
    "    def is_stable(self):                            ## Check if the configuration is stable\n",
    "        r\"\"\"\n",
    "            Check if the configuration is stable.\n",
    "\n",
    "            This function just calls the function is_stable() from the class SandpileConfig.\n",
    "        \"\"\"\n",
    "        return self.sandpile_config.is_stable()\n",
    "\n",
    "\n",
    "    def is_sorted(self):                            ## Check if the configuration has already been sorted\n",
    "        r\"\"\"\n",
    "            Check if the configuration has already been sorted.\n",
    "        \"\"\"\n",
    "        for perm in self.perm_group:\n",
    "            conf = [self.sandpile_config[i] for i in perm]\n",
    "        return is_increasing_list(conf)\n",
    "\n",
    "\n",
    "    def deg(self):                                  ## Returns the degree of the configuration\n",
    "        r\"\"\"\n",
    "            Returns the degree of the configuration.\n",
    "        \"\"\"\n",
    "        return self.sandpile_config.deg()\n",
    "\n",
    "\n",
    "    def topple_sink(self, sorting = True):          ## Topples the sink vertex\n",
    "        r\"\"\"\n",
    "            Topple the sink and change the configuration stored.\n",
    "        \"\"\"\n",
    "        #for vert in self.sandpile_struct.neighbors(self.sandpile_struct.sink()):\n",
    "        #    self.sandpile_config[vert] += 1\n",
    "        c = dict(self.sandpile_config)\n",
    "        for e in self.sandpile_struct.outgoing_edge_iterator(self.sink):\n",
    "            c[e[1]] += e[2]\n",
    "        self.sandpile_config = SandpileConfig(self.sandpile_struct, c)    #type: ignore\n",
    "        if sorting:\n",
    "            self.sort()\n",
    "        return self.sandpile_config\n",
    "    \n",
    "\n",
    "    def topple_vertex(self, vert, sorting = True):                  ## Topples a vertex of the configuration\n",
    "        r\"\"\"\n",
    "            Topple a given vertex of the sandpile. This changes the configuration stored.\n",
    "            \n",
    "            This function just calls the function fire_vertex() from the class SandpileConfig and applies it to self.sandpile_config. \n",
    "        \"\"\"\n",
    "        self.sandpile_config = self.sandpile_config.fire_vertex(vert)\n",
    "        if sorting:\n",
    "            self.sort()\n",
    "        return self.sandpile_config\n",
    "    \n",
    "\n",
    "    def topple_sequence(self, list, sorting = True):                ## Topples a sequence of vertices\n",
    "        r\"\"\"\n",
    "            Topple a list of vertices of the sandpile. This changes the configuration stored.\n",
    "            \n",
    "            This function calls iteratively the function fire_vertex() from the class SandpileConfig and applies it to self.sandpile_config. \n",
    "        \"\"\"\n",
    "        for vert in list:\n",
    "            self.sandpile_config = self.sandpile_config.fire_vertex(vert)\n",
    "        if sorting:\n",
    "            self.sort()\n",
    "        return self.sandpile_config\n",
    "    \n",
    "\n",
    "    def single_topple(self, vert, threshold = 0, sorting = True):   ## Toppling sending one grain for each arc\n",
    "        r\"\"\"\n",
    "            Topple a vertex by sending a grain to each edge.\n",
    "        \"\"\"\n",
    "        neigh = self.sandpile_struct.edges(vert)\n",
    "        for v in neigh:\n",
    "            if (v[1] != self.sink) and (v[2] > threshold):\n",
    "                self.sandpile_config[v[1]] += 1\n",
    "                self.sandpile_config[vert] -= 1\n",
    "        if sorting:\n",
    "            self.sort()\n",
    "        return self.sandpile_config\n",
    "\n",
    "\n",
    "    def __invert__(self, sorting = True):                           ## Topplings until stable\n",
    "        r\"\"\"\n",
    "            Modifies the Sorted Configuration to get the stable configuration.\n",
    "\n",
    "            The function calls the SandpileConfig.__invert__ function, then applies the sorting.\n",
    "        \"\"\"\n",
    "        self.sandpile_config = ~self.sandpile_config\n",
    "        if sorting:\n",
    "            self.sort()\n",
    "        return self.sandpile_config\n",
    "\n",
    "\n",
    "    def level(self):                                                ## Returns the level statistic of the configuration\n",
    "        r\"\"\"\n",
    "            Returns the level of the configuration.\n",
    "        \"\"\"\n",
    "        not_inc_sink = sum([v[2] for v in self.sandpile_struct.to_undirected().edges()]) - self.sandpile_struct.out_degree(self.sink)\n",
    "        return (- not_inc_sink + self.sandpile_config.deg())\n",
    "    \n",
    "\n",
    "    def delay(self, order = [], check_rec = True):                  ## Returns the delay statistic of the configuration\n",
    "        r\"\"\"\n",
    "            Given a reading order of nonsink vertices, this function computes the configuration's delay.\n",
    "\n",
    "            - order         : the order for reading vertices. If undefined, the decreasing order on vertices is assumed.\n",
    "            - check_rec     : this option can be used to override the is_recurrent() call.\n",
    "        \"\"\"\n",
    "        if (not self.is_recurrent()) and check_rec:           # Check if the configuration is recurrent\n",
    "            print(self.sandpile_config)\n",
    "            print(self.sandpile_config.is_recurrent())\n",
    "            self.sandpile_struct.show()\n",
    "            raise Exception(\"The sorted configuration is not recurrent, hence delay is not defined.\")\n",
    "\n",
    "        nonsink_vert = self.vertices\n",
    "\n",
    "        if order == []:                                     # No order has been assigned: take decreasing order\n",
    "            order = copy.copy(nonsink_vert)\n",
    "            order.sort()\n",
    "            order.reverse()\n",
    "        \n",
    "        delay = 0                                                   # The delay value\n",
    "        loop_count = 0                                              # The loop count\n",
    "        not_toppled = copy.copy(nonsink_vert)                                  # A list with the vertices still to be toppled\n",
    "        self.topple_sink(sorting = False)                                  # Start by toppling the sink\n",
    "        while len(not_toppled) > 0:\n",
    "            for ind in order:                               # Search for non-toppled vertices in the right order\n",
    "                value = self.sandpile_config[ind]\n",
    "                if (self.sandpile_struct.out_degree(ind) <= value) and (ind in not_toppled):\n",
    "                                                            # Can be toppled!\n",
    "                    delay += loop_count                             # Raise the delay by suitable amount\n",
    "                    self.topple_vertex(ind, sorting = False)        # Topple the vertex without sorting it back!\n",
    "                    not_toppled.remove(ind)                         # Remove the vertex from not-toppled\n",
    "            loop_count += 1\n",
    "        self.sort()\n",
    "        return delay\n",
    "    \n",
    "\n",
    "    def k_delay(self, order = [], check_rec = True):             ## Returns the NEW delay statistic of the configuration\n",
    "        r\"\"\"\n",
    "            Given a reading order of nonsink vertices, this function computes the configuration's new conjectured delay.\n",
    "            - k             : the multeplicity of all edges (except incident to the sink).\n",
    "            - order         : the order for reading vertices. If undefined, the decreasing order on vertices is assumed.\n",
    "            - check_rec     : this option can be used to override the is_recurrent() call.\n",
    "        \"\"\"\n",
    "        if (not self.is_recurrent()) and check_rec:           # Check if the configuration is recurrent\n",
    "            print(self.sandpile_config)\n",
    "            print(self.sandpile_config.is_recurrent())\n",
    "            self.sandpile_struct.show()\n",
    "            raise Exception(\"The sorted configuration is not recurrent, hence delay is not defined.\")\n",
    "\n",
    "        k = max([self.sandpile_struct.degree(v) for v in self.vertices])\n",
    "\n",
    "        nonsink_vert = self.vertices\n",
    "        n = len(nonsink_vert)\n",
    "\n",
    "        if order == []:                                     # No order has been assigned: take decreasing order\n",
    "            order = copy.copy(nonsink_vert)\n",
    "            order.sort()\n",
    "            order.reverse()\n",
    "\n",
    "        toppl = [0]*n                                           # Stores information on how many partial topplings are still needed\n",
    "        finalv = [k]*n                                          # We exit the loop when toppl == finalv\n",
    "        delay = 0\n",
    "        plus = 0\n",
    "        self.topple_sink(sorting = False)                               # Start by toppling the sink\n",
    "        while toppl != finalv:                               # Until everything has been toppled k times...\n",
    "            for i in range(len(order)):\n",
    "                if (self.sandpile_struct.out_degree(order[i]) <= self.sandpile_config[order[i]]) and (toppl[i] == 0):\n",
    "                                                                        # Can be toppled for the first time!\n",
    "                    self.single_topple(order[i], threshold = toppl[i], sorting = False)\n",
    "                    toppl[i] += 1\n",
    "                    delay += plus\n",
    "                else:\n",
    "                    if toppl[i] < finalv[i] and toppl[i] > 0:                   # Topple later time...\n",
    "                        self.single_topple(order[i], threshold = toppl[i], sorting = False)\n",
    "                        toppl[i] += 1\n",
    "            plus += 1\n",
    "        #print(\"The configuration {} has k-delay {}\".format(self.sandpile_config, delay))\n",
    "        self.sort()\n",
    "        return delay\n",
    "\n",
    "\n",
    "    def show(self, sink = True, colors = False, heights = False, directed = False):     ## Returns a drawing of the configuration\n",
    "        r\"\"\"\n",
    "            Returns a drawing of the sorted sandpile configuration.\n",
    "        \"\"\"\n",
    "        # Define the color of each part\n",
    "        palette = rainbow(len(self.perm_group)+1) # type: ignore\n",
    "        if sink:\n",
    "            col ={**{palette[0]:[self.sink]},**{palette[i+1]:self.perm_group[i] for i in range(len(self.perm_group))}}\n",
    "        else:\n",
    "            col = {palette[i+1]:self.perm_group[i] for i in range(len(self.perm_group))}\n",
    "        \n",
    "        # Call SandpileConfig.show()\n",
    "        self.sandpile_config.show(sink = sink, colors = colors, heights = heights, directed = directed, vertex_colors = col)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "                    #####################################################\n",
    "                    #                   Sorted Sandpile                 #\n",
    "                    #####################################################\n",
    "\n",
    "class SortedSandpile():\n",
    "\n",
    "    def __init__(self, graph, sink, permut, opt=[], sort_rec = []):    ## Initialize the class SortedSandpile\n",
    "        r\"\"\"\n",
    "            Definition of the class SortedSandpile.\n",
    "            \n",
    "            The arguments given are a sandpile and a partition of the vertex set (without sink).\n",
    "        \"\"\"\n",
    "\n",
    "        ### TODO: check if the arguments given correspond to a good SandpileSortConfig\n",
    "        \n",
    "        self.sandpile_struct = Sandpile(graph, sink) # type: ignore                         # Define the Sandpile structure\n",
    "        self.vertices = self.sandpile_struct.nonsink_vertices()                             # Define the nonsink vertices\n",
    "        self.perm_group = permut                                                            # Define the permutation group on the graph vertices\n",
    "        self.specific_opt = opt                                                             # Define the specific options, to optimize in specific cases\n",
    "        self.sorted_rec = sort_rec                                                          # Eventually store the sorted recurrent configurations if computed\n",
    "\n",
    "\n",
    "    def __repr__(self):                                 ## Description of SortedSandpile class\n",
    "        return \"A sorted sandpile on vertices {} and sink {}.\".format(self.sandpile_struct.vertices(), self.sandpile_struct.sink())\n",
    "    \n",
    "\n",
    "    def _max_stable(self):                              ## Returns maximal stable configuration\n",
    "        r\"\"\"\n",
    "            Returns the maximal stable sorted configuration of the sandpile.\n",
    "        \"\"\"\n",
    "        return SandpileSortConfig(self.sandpile_struct, {v:self.sandpile_struct.out_degree(v)-1 for v in self.vertices}, self.perm_group)\n",
    "    \n",
    "    \n",
    "    def nonsink_vertices(self):                         ## Returns non-sink vertices\n",
    "        r\"\"\"\n",
    "            Returns the non-sink vertices of the sorted sandpile.\n",
    "        \"\"\"\n",
    "        return self.sandpile_struct.nonsink_vertices()\n",
    "    \n",
    "\n",
    "    def sink(self):                                     ## Returns sink\n",
    "        r\"\"\"\n",
    "            Returns the sink of the sorted sandpile.\n",
    "        \"\"\"\n",
    "        return self.sandpile_struct.sink()\n",
    "    \n",
    "\n",
    "    def sandpile(self):                                 ## Returns the unsorted sandpile\n",
    "        r\"\"\"\n",
    "            Returns the sandpile without sorting.\n",
    "        \"\"\"\n",
    "        return self.sandpile_struct\n",
    "\n",
    "    \n",
    "    def reduced_laplacian(self):                        ## Reduced Laplacian\n",
    "        r\"\"\"\n",
    "            Returns the reduced Laplacian matrix of the sandpile.\n",
    "        \"\"\"\n",
    "        return self.sandpile_struct.reduced_laplacian()\n",
    "\n",
    "\n",
    "    def simple_recurrents(self, verbose = True):                            ## Computes the simple recurrents\n",
    "        r\"\"\"\n",
    "            Returns the list of recurrent configurations ignoring the action of perm_group.\n",
    "\n",
    "            It's a call of the recurrents() function from Sandpile class.\n",
    "        \"\"\"\n",
    "        return self.sandpile_struct.recurrents(verbose = verbose)\n",
    "    \n",
    "\n",
    "    def sorted_recurrents(self, option = 2):                                ## Computes a list of all sorted recurrent configurations\n",
    "        r\"\"\"\n",
    "            Computes the sorted recurrent configurations.\n",
    "\n",
    "            - option        : based on the value the search algorithm changes\n",
    "                = 0     : calls the recurrent() function from Sandpile class [default].\n",
    "                = 1     : is a modified version of recurrent() function that ignores the same orbits all together.\n",
    "                = 2     : modified version of the previous, where the duplicate search is more efficient since we sort by configuration degree.\n",
    "        \"\"\"\n",
    "        if option == 0:                                                         ## OPTION 0: computes all recurrents and then quotient by perm_group action\n",
    "            simpl_rec = self.simple_recurrents()        # Compute all the recurrent configurations\n",
    "            for i in range(len(simpl_rec)):             # Reorder elements in each configuration\n",
    "                temp = SandpileSortConfig(self.sandpile_struct, simpl_rec[i], self.perm_group)\n",
    "                X = temp.sort()\n",
    "                simpl_rec[i] = [X[j] for j in list(X)]  # Change dictionary in list\n",
    "            simpl_rec.sort()                            # Remove duplicates\n",
    "            simpl_rec = list(simpl_rec for simpl_rec,_ in itertools.groupby(simpl_rec))\n",
    "            # Now back to a dictionary...\n",
    "            self.sorted_rec = []\n",
    "            for i in range(len(simpl_rec)):\n",
    "                sort_dict = {self.vertices[j]:simpl_rec[i][j] for j in range(len(simpl_rec[i]))}\n",
    "                self.sorted_rec = self.sorted_rec + [sort_dict]\n",
    "            return self.sorted_rec\n",
    "\n",
    "        elif option == 1:                                                         ## OPTION 1: modified version of 0, doesn't append the equivalent configurations\n",
    "            sorted_temp = []                    # Empty sorted_rec list         \n",
    "            active = [self._max_stable()]       # Start just with the maximal stable\n",
    "            while active:                       # While the active list is non-empty...\n",
    "                c = active.pop()\n",
    "                sorted_temp.append(c)\n",
    "                for v in self.vertices:\n",
    "                    cnext = deepcopy(c) # type: ignore                   # Deepcopy the configuration\n",
    "                    cnext.sandpile_config[v] += 1                        # Add 1 to a vertex in the configuration\n",
    "                    cnext.sandpile_config = ~cnext.sandpile_config       # Stabilize the new configuration\n",
    "                    cnext.sort()\n",
    "                    if (cnext not in active) and (cnext not in sorted_temp) and (cnext != c):            # If it is still to be discovered and not repeating...\n",
    "                        active.insert(0,cnext)                           # Instead of appending, put at the start of list!\n",
    "            # Now convert all SandpileSortConfig to dictionaries...\n",
    "            self.sorted_rec = [x.sandpile_config for x in sorted_temp]\n",
    "            return self.sorted_rec\n",
    "        \n",
    "        elif option == 2:                                                         ## OPTION 2: modified version of 1 that sorts the recurrent configurations and active by degree (invariant for sorting).\n",
    "                                                                                  #            The idea is to make the search in active and sorted_temp more efficient.\n",
    "            max_deg = self._max_stable().deg()\n",
    "            sorted_temp = []                                                                    # Empty sorted_rec list     \n",
    "            sorted_dict = {i:[] for i in range(max_deg+1)}                                      # Empty sorted_rec dictionary, keyed by degree   \n",
    "            active = [self._max_stable()]                                                       # Empty active list\n",
    "            active_dict = {**{max_deg:[self._max_stable()]},**{i:[] for i in range(max_deg)}}       # Empty active dictionary, keyed by degree\n",
    "            while active:                       # While the active list is non-empty...\n",
    "                c = active.pop()\n",
    "                deg_c = c.deg()\n",
    "                active_dict[deg_c].pop()\n",
    "                sorted_temp.append(c)               # Append to sorted list\n",
    "                sorted_dict[deg_c].insert(0,c)      # Append to sorted list dictionary\n",
    "                for v in self.vertices:\n",
    "                    cnext = deepcopy(c) # type: ignore                   # Deepcopy the configuration\n",
    "                    cnext.sandpile_config[v] += 1                        # Add 1 to a vertex in the configuration\n",
    "                    cnext.sandpile_config = ~cnext.sandpile_config       # Stabilize the new configuration\n",
    "                    cnext.sort()\n",
    "                    deg_cnext = cnext.deg()\n",
    "                    if (cnext not in active_dict[deg_cnext]) and (cnext not in sorted_dict[deg_cnext]) and (cnext != c):            # If it is still to be discovered and not repeating...\n",
    "                        active.insert(0,cnext)\n",
    "                        active_dict[deg_cnext].insert(0,cnext)\n",
    "            # Now convert all SandpileSortConfig to dictionaries...\n",
    "            self.sorted_rec = [x.sandpile_config for x in sorted_temp]\n",
    "            return self.sorted_rec\n",
    "\n",
    "        else:\n",
    "            raise Exception(\"The given option is not valid.\")\n",
    "    \n",
    "\n",
    "    def q_Polynomial(self, opt = 2, override = False):                      ## Computes the q,t polynomial on (level, delay)\n",
    "        r\"\"\"\n",
    "            Returns the q - polynomial corresponding to the sorted sandpile's recurrent configurations.\n",
    "\n",
    "            - order     : if specified, it fixes the reading order for the delay statistic.\n",
    "            - opt       : if specified, it uses a different computing algorithm.\n",
    "            - override  _ if specified, the sorted recurrents are computed even if sorted_rec is non-empty.\n",
    "        \"\"\"\n",
    "        R = FractionField(QQ['q'])      # type: ignore\n",
    "        q = R.gen()\n",
    "        poly = 0*q                                  # Define the polynomial as 0\n",
    "\n",
    "        if self.sorted_rec == [] or override:       # If sorted recurrents still to be computed...\n",
    "            self.sorted_recurrents(option=opt)          # ...compute them!\n",
    "        \n",
    "        for config in self.sorted_rec:      # Compute the polynomial\n",
    "            sortedconfig = SandpileSortConfig(self.sandpile_struct, config, self.perm_group, sort = False, verts = self.vertices)\n",
    "            q_exp = sortedconfig.level()\n",
    "            #print(\"Configurazione {} con livello {} e delay {}\".format(sortedconfig.sandpile_config, q_exp, t_exp))\n",
    "            poly = poly + (q**q_exp)\n",
    "        return poly\n",
    "\n",
    "\n",
    "    def qt_Polynomial(self, ordered = [], opt = 2, override = False):       ## Computes the q,t polynomial on (level, delay)\n",
    "        r\"\"\"\n",
    "            Returns the q,t - polynomial corresponding to the sorted sandpile's recurrent configurations.\n",
    "\n",
    "            - order     : if specified, it fixes the reading order for the delay statistic.\n",
    "            - opt       : if specified, it uses a different computing algorithm.\n",
    "            - override  : if specified, the sorted recurrents are computed even if sorted_rec is non-empty.\n",
    "        \"\"\"\n",
    "        R = FractionField(QQ['q, t'])      # type: ignore\n",
    "        q,t = R.gens()\n",
    "        poly = 0*q*t                            # Define the polynomial as 0\n",
    "\n",
    "        if self.sorted_rec == [] or override:   # If sorted recurrents still to be computed...\n",
    "            self.sorted_recurrents(option=opt)        # ...compute them!\n",
    "        \n",
    "        # TODO: be sure that the delay doesn't depend on the order in the same orbit...\n",
    "\n",
    "        if ordered == []:                   # If there is no explicit order check for a specific one\n",
    "            if self.specific_opt[0] == \"clique-indep\" or self.specific_opt[0] == \"mul-clique-indep\":          # The reading order that defines delay...\n",
    "                ordered = self.specific_opt[2]\n",
    "            elif self.specific_opt[0] == \"gen-clique-indep\" or self.specific_opt[0] == \"mulgen-clique-indep\":\n",
    "                ordered = self.specific_opt[3]\n",
    "            \n",
    "        if self.specific_opt[0] == \"mul-clique-indep\":              # Compute the polynomial with k_delay\n",
    "            for config in self.sorted_rec:\n",
    "                sortedconfig = SandpileSortConfig(self.sandpile_struct, config, self.perm_group, sort = False, verts = self.vertices)\n",
    "                q_exp = sortedconfig.level()\n",
    "                t_exp = sortedconfig.k_delay(order = ordered, check_rec=False)\n",
    "                #print(\"Configurazione {} con livello {} e delay {}\".format(sortedconfig.sandpile_config, q_exp, t_exp))\n",
    "                poly = poly + (q**q_exp) * (t**t_exp)\n",
    "        else:                                                       # Compute the polynomial with regular delay\n",
    "            for config in self.sorted_rec:\n",
    "                sortedconfig = SandpileSortConfig(self.sandpile_struct, config, self.perm_group, sort = False, verts = self.vertices)\n",
    "                q_exp = sortedconfig.level()\n",
    "                t_exp = sortedconfig.k_delay(order = ordered, check_rec=False)\n",
    "                #print(\"Configurazione {} con livello {} e delay {}\".format(sortedconfig.sandpile_config, q_exp, t_exp))\n",
    "                poly = poly + (q**q_exp) * (t**t_exp)\n",
    "        \n",
    "        return poly\n",
    "    \n",
    "\n",
    "    def associated_ring(self, coeff_ring, order = [], homog = False):       ## Compute the associated ring\n",
    "        r\"\"\"\n",
    "            Compute the ring associated to the sorted sandpile. The possible arguments are:\n",
    "                - coeff_ring    : specify the coefficient ring for the polynomial ring.\n",
    "                - order         : the vertex order associated to variables x0, ..., xn (optional).\n",
    "                - homog         : asks whether to construct the homogeneous ideal or not (optional, default is False).\n",
    "\n",
    "            The function returns a list with the quotient ring and a tuple with the polynomial ring and the ideal.\n",
    "        \"\"\"\n",
    "        if not homog:                                           ## Not homogeneous\n",
    "            # Define the multivariate polynomial ring\n",
    "            R = PolynomialRing(coeff_ring, ['x%s'%v for v in range(len(self.vertices))])    #type: ignore\n",
    "            t = R.gens()\n",
    "            if order == []:\n",
    "                x = {self.vertices[i]:t[i] for i in range(len(self.vertices))}      # Dictionary with variables\n",
    "            else:\n",
    "                x = {order[i]:t[i] for i in range(len(self.vertices))}\n",
    "\n",
    "            # Create a list with generators for the ideal\n",
    "            ideal_gens = []\n",
    "            for v in self.vertices:         # Toppling polynomials\n",
    "                poly = - x[v]**(self.sandpile_struct.out_degree(v)) + R.prod([x[e[1]] for e in self.sandpile_struct.edges(v, labels = False) if e[1] in self.vertices])\n",
    "                ideal_gens.append(poly)\n",
    "            I = R.ideal(ideal_gens)         # Define the ideal\n",
    "\n",
    "            return (R, I)\n",
    "        else:                                                   ## Homogeneous\n",
    "            # Define the multivariate polynomial ring\n",
    "            R = PolynomialRing(coeff_ring, ['x%s'%v for v in range(len(self.vertices)+1)])    #type: ignore\n",
    "            t = R.gens()\n",
    "            if order == []:\n",
    "                order = self.vertices + [self.sink()]\n",
    "            x = {order[i]:t[i] for i in range(len(self.vertices)+1)}\n",
    "\n",
    "            # Create a list with generators for the ideal\n",
    "            ideal_gens = [x[self.sink()]-1]\n",
    "            for v in self.vertices:         # Toppling polynomials\n",
    "                poly = - x[v]**(self.sandpile_struct.out_degree(v)) + R.prod([x[e[1]] for e in self.sandpile_struct.edges(v, labels = False)])\n",
    "                ideal_gens.append(poly)\n",
    "            I = R.ideal(ideal_gens)         # Define the ideal\n",
    "\n",
    "            return (R, I)\n",
    "\n",
    "\n",
    "    def symm_poly(self, coeff_ring, config, order = []):                    ## Given a configuration, this function returns the symmetrized\n",
    "        r\"\"\"\n",
    "            This function computes the polynomial symmetric with respect to perm_group associated to the configuration config.\n",
    "        \"\"\"\n",
    "        (R,I) = self.associated_ring(coeff_ring, order = order)    # Define the ring\n",
    "        t = R.gens()\n",
    "        if order == []:\n",
    "            order = self.vertices\n",
    "        x = {order[i]:t[i] for i in range(len(self.vertices))}\n",
    "\n",
    "        poly = R.prod([x[v]**config[v] for v in self.vertices])\n",
    "        Sn = SymmetricGroup(range(len(order)))      #type:ignore\n",
    "        for subgr in self.perm_group:\n",
    "            new_poly = 0\n",
    "            indexes = [i for i in range(len(order)) if order[i] in subgr]\n",
    "            for sigma in Permutations(indexes):     #type: ignore\n",
    "                ext_dict = {**{v:v for v in order if v not in subgr},**{subgr[i]:order[sigma[i]] for i in range(len(indexes))}}\n",
    "                ext_perm = [ext_dict[v] for v in order]\n",
    "                ext_sigma = Sn([ext_perm.index(v) for v in order])   #type: ignore\n",
    "                new_poly = new_poly + poly(*ext_sigma(t))\n",
    "            poly = new_poly\n",
    "        return poly\n",
    "    \n",
    "\n",
    "    def sortrec_ideal(self, coeff_ring, sorted = True, opt = 2, override = False, order = [], homog = False):     ## Compute the sorted recurrent ideal\n",
    "        r\"\"\"\n",
    "            Compute the ideal to sorted recurrents. The possible arguments are:\n",
    "                - coeff_ring    : specify the coefficient ring for the polynomial ring.\n",
    "                - sorted        : boolean, it indicates if the considered sandpile is sorted (optional, default is True).\n",
    "                - opt           : option for computing sorted recurrents (optional).\n",
    "                - override      : boolean, if true the sorted recurrents are computed even if sorted_rec is non-empty (optional, default is False)\n",
    "                - order         : the vertex order associated to variables x0, ..., xn (optional).\n",
    "                - homog         : asks whether to construct the homogeneous ideal or not (optional, default is False).\n",
    "\n",
    "            The function returns a list with the quotient ring, the polynomial ring and the ideal.\n",
    "        \"\"\"\n",
    "        if not homog:\n",
    "            if self.sorted_rec == [] or override:                       # Computes the sorted recurrents if necessary\n",
    "                self.sorted_recurrents(option = opt)\n",
    "\n",
    "            (R,I) = self.associated_ring(coeff_ring, sorted=sorted, order=order)     # Construct the associated ring\n",
    "            t = R.gens()\n",
    "            if order == []:\n",
    "                order = self.vertices\n",
    "            x = {order[i]:t[i] for i in range(len(self.vertices))}\n",
    "            \n",
    "            ideal_gens = []                                             # Compute ideal generators for R\n",
    "            for conf in self.sorted_rec:\n",
    "                if sorted:\n",
    "                    poly = self.symm_poly(coeff_ring, conf, order=order)\n",
    "                else:\n",
    "                    poly = R.prod([x[v]**conf[v] for v in self.vertices])\n",
    "                ideal_gens.append(poly)\n",
    "            J = R.ideal(ideal_gens)\n",
    "\n",
    "            return (R,I,J)\n",
    "        else:\n",
    "            if self.sorted_rec == [] or override:                       # Computes the sorted recurrents if necessary\n",
    "                self.sorted_recurrents(option = opt)\n",
    "\n",
    "            (R,I) = self.associated_ring(coeff_ring, sorted=sorted, order=order, homog=True)     # Construct the associated ring\n",
    "            t = R.gens()\n",
    "            if order == []:\n",
    "                order = self.vertices + [self.sink()]\n",
    "            x = {order[i]:t[i] for i in range(len(self.vertices)+1)}\n",
    "\n",
    "            ideal_gens = []                                             # Compute ideal generators for R\n",
    "            for conf in self.sorted_rec:\n",
    "                if sorted:\n",
    "                    poly = self.symm_poly(coeff_ring, conf, order=[v for v in order if v != self.sink()])\n",
    "                else:\n",
    "                    poly = R.prod([x[v]**conf[v] for v in self.vertices])\n",
    "                ideal_gens.append(poly)\n",
    "            J = R.ideal(ideal_gens)\n",
    "\n",
    "            return (R,I,J)\n",
    "    \n",
    "    \n",
    "    def show(self, default = False):                                        ## Function that displays the Sorted Sandpile\n",
    "        r\"\"\"\n",
    "            This function plots the sorted sandpile. The possible arguments are:\n",
    "            - basic = False : if True, the representation is the same as Sandpile.show().\n",
    "\n",
    "            If specific_opt is non-empty, the show function uses specific parameters:\n",
    "            - default                   : call to the Sandpile.show() function\n",
    "            - clique-independent graph  : call to the Sandpile.show() function fixing the position of the vertices,\n",
    "                                          the sink in the center and the nonsink in a circle.\n",
    "        \"\"\"\n",
    "        if self.specific_opt == [] or default:                         # Default\n",
    "            if self.sandpile_struct.has_multiple_edges():\n",
    "                self.sandpile_struct.show(edge_labels=True)\n",
    "            else:\n",
    "                self.sandpile_struct.show()\n",
    "        elif self.specific_opt[0] == \"clique-indep\":        # Clique-independent graph\n",
    "            [mu, nu] = self.specific_opt[1]\n",
    "            mu_num = sum(mu)\n",
    "            nu_num = sum(nu)\n",
    "            # Define the position of each vertex\n",
    "            positions = {**{0:(0,0)},** {i+1:(-np.sin(2*np.pi*i/(mu_num + nu_num)), np.cos(2*np.pi*i/(mu_num + nu_num)))  for i in range(mu_num + nu_num)}}\n",
    "            # Define the color of each part\n",
    "            palette = rainbow(len(mu) + len(nu) + 1) # type: ignore\n",
    "            col = {**{palette[0]:[0]},**{palette[i+1]:self.perm_group[i] for i in range(len(nu) + len(mu))}}\n",
    "\n",
    "            G = Graph(self.sandpile_struct.dict()).to_undirected() # type: ignore\n",
    "            \n",
    "            G.show(pos = positions, vertex_colors = col)\n",
    "        elif self.specific_opt[0] == \"gen-clique-indep\":        # Generalized clique-independent graph\n",
    "            vertex_set = self.specific_opt[1].vertices()\n",
    "            cliq = []\n",
    "            indep = []\n",
    "            for vert in vertex_set:\n",
    "                if self.specific_opt[2][vert] > 0:\n",
    "                    cliq.append(vert)\n",
    "                else:\n",
    "                    indep.append(vert)\n",
    "            palette = rainbow(2)    #type: ignore\n",
    "            col = {palette[0]:cliq, palette[1]:indep}    #type: ignore\n",
    "            self.specific_opt[1].show(vertex_colors = col, vertex_labels=self.specific_opt[2])\n",
    "        elif self.specific_opt[0] == \"mul-clique-indep\":            # Multi clique-independent graph\n",
    "            [mu, nu] = self.specific_opt[1]\n",
    "            mu_num = sum(mu)\n",
    "            nu_num = sum(nu)\n",
    "            # Define the position of each vertex\n",
    "            positions = {**{0:(0,0)},**{i+1:(-np.sin(2*np.pi*i/(mu_num + nu_num)), np.cos(2*np.pi*i/(mu_num + nu_num)))  for i in range(mu_num + nu_num)}}\n",
    "            # Define the color of each part\n",
    "            palette = rainbow(len(mu) + len(nu) + 1) # type: ignore\n",
    "            col = {**{palette[0]:[0]},**{palette[i+1]:self.perm_group[i] for i in range(len(nu) + len(mu))}}\n",
    "\n",
    "            G = Graph(self.sandpile_struct.dict()).to_undirected() # type: ignore\n",
    "            \n",
    "            G.show(pos = positions, vertex_colors = col, edge_labels = True)\n",
    "        elif self.specific_opt[0] == \"mulgen-clique-indep\":    # Multi generalized clique-independent graph\n",
    "            vertex_set = self.specific_opt[1].vertices()\n",
    "            cliq = []\n",
    "            indep = []\n",
    "            for vert in vertex_set:\n",
    "                if self.specific_opt[2][vert] > 0:\n",
    "                    cliq.append(vert)\n",
    "                else:\n",
    "                    indep.append(vert)\n",
    "            palette = rainbow(2)    #type: ignore\n",
    "            col = {palette[0]:cliq, palette[1]:indep}    #type: ignore\n",
    "            self.specific_opt[1].show(vertex_colors = col, vertex_labels=self.specific_opt[2], edge_labels=False)\n",
    "    \n",
    "\n",
    "    def export(self, saveopt = 0, opt = 2):                 ## Export informations for the Sorted Sandpile\n",
    "        r\"\"\"\n",
    "            This function returns the critical information of the sorted sandpile in a format that can be saved using pickle.\n",
    "            If saveopt = 0, the function returns a list with:\n",
    "                -   saveopt\n",
    "                -   a dictionary of the underlying graph\n",
    "                -   the sink of the sandpile\n",
    "                -   the permutation group\n",
    "                -   the specific options for the sandpile\n",
    "                -   the order of vertices for...\n",
    "                -   ...the list of sorted recurrents\n",
    "                -   the qt-polynomial associated to the sorted sandpile.\n",
    "        \"\"\"\n",
    "        qt_poly = self.qt_Polynomial(opt = opt)\n",
    "        key_list = list(self.sorted_rec[0].keys())\n",
    "        conflist = [[conf[i] for i in key_list] for conf in self.sorted_rec]\n",
    "        return [saveopt, self.sandpile_struct.dict(), self.sandpile_struct.sink(), self.perm_group, self.specific_opt, key_list, conflist, qt_poly]\n",
    "\n",
    "\n",
    "    def save(self, namefile, saveopt = 0, opt = 2):         ## Save the information on a file\n",
    "        r\"\"\"\n",
    "            This function saves the critical information of the sorted sandpile in a namefile\n",
    "        \"\"\"\n",
    "        info = self.export(saveopt = saveopt, opt = opt)\n",
    "        \n",
    "        with open(namefile, 'wb') as handle:\n",
    "            pickle.dump(info, handle)\n",
    "    \n",
    "\n",
    "    def load(namefile):                                     ## Load the information for a Sandpile\n",
    "        r\"\"\"\n",
    "            This function reads a file and returns a sorted sandpile with the information.\n",
    "        \"\"\"\n",
    "        with open(namefile, 'rb') as handle:\n",
    "            info = pickle.load(handle)\n",
    "\n",
    "        if info[0] == 0:\n",
    "            sorted_rec = []\n",
    "            keys = info[5]\n",
    "            for conf in info[6]:\n",
    "                sort_conf = {keys[i]:conf[i] for i in range(len(keys))}\n",
    "                sorted_rec.append(sort_conf)\n",
    "            S = SortedSandpile(info[1], info[2], info[3], opt=info[4], sort_rec = sorted_rec)\n",
    "            return S\n",
    "        else:\n",
    "            raise ImportError(\"The file cannot be read.\")\n",
    "\n",
    "\n",
    "                    ########################################################\n",
    "                    #                   Specific Sandpiles                 #\n",
    "                    ########################################################\n",
    "\n",
    "\n",
    "def CliqueIndependent_SortedSandpile(mu, nu):                                                                                           ## Specific type of Sandpile\n",
    "    r\"\"\"\n",
    "        Construction of a Sorted Sandpile on the clique-independent graph given by parameters:\n",
    "            - mu    : partition associated to the number and size of cliques in the graph.\n",
    "            - nu    : partition associated to the number and size of independents in the graph.\n",
    "    \"\"\"\n",
    "    mu_num = sum(mu)                                    # Number of independent vertices\n",
    "    nu_num = sum(nu)                                    # Number of vertices in cliques\n",
    "    d = {0 : [i+1 for i in range(mu_num + nu_num)]}     # Initialize the dictionary that will define the graph, link the sink to each vertex\n",
    "    perm_group = []                                     # Initialize the permutation group acting on the graph\n",
    "\n",
    "    part_first = 1                                      # Keeps track of first vertex of current part\n",
    "    for part_nu in nu:                                                  # Add edges for independent vertices. For each part...\n",
    "        for i in range(part_nu):                                        # ...for each vertex in the part...\n",
    "            d[part_first + i] = [vert for vert in range(mu_num + nu_num + 1) if (vert < part_first) or (vert >= part_first + part_nu)]\n",
    "                                                                        # ...add all edges except for other vertices in part_nu    \n",
    "        perm_group.append([part_first+j for j in range(part_nu)])       # Add the permutation orbit for the nu_part\n",
    "        part_first += part_nu\n",
    "    mu_rev = copy.copy(mu)              # We need the reversed partition mu...\n",
    "    mu_rev.reverse()\n",
    "    for part_mu in mu_rev:\n",
    "        for i in range(part_mu):\n",
    "            d[part_first + i] = [vert for vert in range(mu_num + nu_num + 1) if vert != part_first + i]\n",
    "        perm_group.append([part_first+j for j in range(part_mu)])       # Add the permutation orbit for the mu_part\n",
    "        part_first += part_mu\n",
    "\n",
    "    ordered = []\n",
    "    for i in range(len(mu)):\n",
    "        temp = copy.copy(perm_group[len(perm_group)-i-1])\n",
    "        temp.sort()\n",
    "        ordered = ordered + temp\n",
    "    for j in range(len(nu)):\n",
    "        temp = copy.copy(perm_group[len(nu)-j-1])\n",
    "        temp.sort()\n",
    "        temp.reverse()\n",
    "        ordered = ordered + temp\n",
    "    \n",
    "    G = Graph(d)            # type: ignore      # Define the clique-independent graph\n",
    "    specif_opt = [\"clique-indep\", [mu, nu], ordered]\n",
    "    '''\n",
    "        Specific Options:\n",
    "        1-  list of the defining partitions\n",
    "        2-  reading order\n",
    "    '''\n",
    "    S = SortedSandpile(G, 0, perm_group, specif_opt)\n",
    "    return S\n",
    "\n",
    "\n",
    "def General_CliqueIndependent_SortedSandpile(cells_graph, card_cell, order_cells = []):                                                 ## Specific type of Sandpile\n",
    "    r\"\"\"\n",
    "        Construction of a Sorted Sandpile on the generalized clique-independent graph. Arguments are a graph and a dictionary with values for vertices, such that:\n",
    "            - nodes:    represents a clique or an independent component with |card_cell[node]| vertices.\n",
    "                        If the sign of card_cell[node] is:\n",
    "                            - positive:     we have a clique.\n",
    "                            - negative:     we have an independent.\n",
    "            - edges:    each edge correspond to all possible edges between the two cells connected.\n",
    "    \"\"\"\n",
    "    cell_list = cells_graph.vertices()\n",
    "    \n",
    "    if order_cells == []:\n",
    "        order_cells = copy.copy(cell_list)\n",
    "    \n",
    "    num_vert = sum([abs(card_cell[i]) for i in cell_list])      # Set the total number of vertices for sandpile\n",
    "\n",
    "    dict_cell = {}                                              # Dictionary \"cell -> list vertices\"\n",
    "    index_next_cell = 1\n",
    "    for cell in cell_list:\n",
    "        dict_cell.update({cell:[index_next_cell + j for j in range(abs(card_cell[cell]))]})\n",
    "        index_next_cell += abs(card_cell[cell])\n",
    "\n",
    "    order = []                                                  # Reading order for qt-Polynomials\n",
    "    for cell in order_cells:                                    \n",
    "        order = order + dict_cell[cell]\n",
    "    \n",
    "    edges_set = {0:[i+1 for i in range(num_vert)]}              # Set of edges, sink to everyone\n",
    "    perm_group = []                                             # Set the permutation group\n",
    "\n",
    "    now = 1\n",
    "    index_next_cell = 1\n",
    "    for cell in cell_list:                              # Add the cell\n",
    "        perm_group.append(dict_cell[cell])\n",
    "\n",
    "        for vert in range(abs(card_cell[cell])):\n",
    "            if card_cell[cell] > 0:                         # Add for clique\n",
    "                next_neigh = [0] + [index_next_cell + j for j in range(abs(card_cell[cell])) if index_next_cell + j != now]\n",
    "            else:                                           # Add nothing for independent\n",
    "                next_neigh = [0]\n",
    "            # Add complete edges with other cells...\n",
    "            for neigh_cell in cells_graph.neighbors(cell):\n",
    "                next_neigh = next_neigh + dict_cell[neigh_cell]\n",
    "\n",
    "            # Add to the dictionary\n",
    "            edges_set.update({now:next_neigh})\n",
    "            now += 1\n",
    "\n",
    "        index_next_cell += abs(card_cell[cell])\n",
    "\n",
    "    G = Graph(edges_set)    #type: ignore\n",
    "    spec_opt = [\"gen-clique-indep\", cells_graph, card_cell, order]\n",
    "    '''\n",
    "        Specific Options:\n",
    "        1-  Cell graph\n",
    "        2-  Cell cardinality dictionary\n",
    "        3-  Reading order (TODO)\n",
    "    '''\n",
    "    S = SortedSandpile(G, 0, perm_group, spec_opt)\n",
    "    return S\n",
    "\n",
    "\n",
    "def Multi_CliqueIndependent_SortedSandpile(mu, nu, kmul, hmul = -1):                                                                    ## Specific type of Sandpile\n",
    "    r\"\"\"\n",
    "        Construction of the Sorted Sandpile, given two partitions mu, nu, where edges have multeplicity k in each clique and multeplicity h between components.\n",
    "    \"\"\"\n",
    "    if hmul == -1:     # If third argument is not given, assume it is equal to k\n",
    "        hmul = kmul\n",
    "\n",
    "    mu_num = sum(mu)                                    # Number of independent vertices\n",
    "    nu_num = sum(nu)                                    # Number of vertices in cliques\n",
    "    d = {0 : [i+1 for i in range(mu_num + nu_num)]}     # Initialize the dictionary that will define the graph, link the sink to each vertex\n",
    "    perm_group = []                                     # Initialize the permutation group acting on the graph\n",
    "\n",
    "    part_first = 1                                      # Keeps track of first vertex of current part\n",
    "    for part_nu in nu:                                          # Add edges for independent vertices. For each part...\n",
    "        for i in range(part_nu):\n",
    "            indep = [vert for vert in range(mu_num + nu_num + 1) for mult in range(kmul-1) if (part_first <= vert) and (vert < part_first + part_nu) and (vert != part_first + i)]\n",
    "            others = [vert for vert in range(mu_num + nu_num + 1) for mult in range(hmul) if ((0 < vert) and (vert < part_first)) or (vert >= part_first + part_nu)]\n",
    "            d[part_first + i] = [0] + indep + others\n",
    "                                                                        # ...add all edges except for other vertices in part_nu    \n",
    "        perm_group.append([part_first+j for j in range(part_nu)])       # Add the permutation orbit for the nu_part\n",
    "        part_first += part_nu\n",
    "    mu_rev = copy.copy(mu)                                              # We need the reversed partition mu...\n",
    "    mu_rev.reverse()\n",
    "    for part_mu in mu_rev:                                      # Add edges for clique sets. For each part...\n",
    "        for i in range(part_mu):\n",
    "            clique = [vert for vert in range(mu_num + nu_num + 1) for mult in range(kmul) if (part_first <= vert) and (vert < part_first + part_mu) and (vert != part_first + i)]\n",
    "            others = [vert for vert in range(mu_num + nu_num + 1) for mult in range(hmul) if ((0 < vert) and (vert < part_first)) or (vert >= part_first + part_mu)]\n",
    "            d[part_first + i] = [0] + clique + others\n",
    "        perm_group.append([part_first+j for j in range(part_mu)])       # Add the permutation orbit for the mu_part\n",
    "        part_first += part_mu\n",
    "\n",
    "    ordered = []\n",
    "    for i in range(len(mu)):\n",
    "        temp = copy.copy(perm_group[len(perm_group)-i-1])\n",
    "        temp.sort()\n",
    "        ordered = ordered + temp\n",
    "    for j in range(len(nu)):\n",
    "        temp = copy.copy(perm_group[len(nu)-j-1])\n",
    "        temp.sort()\n",
    "        ordered = ordered + temp\n",
    "    \n",
    "    G = Graph(d)            # type: ignore      # Define the clique-independent graph\n",
    "    specif_opt = [\"mul-clique-indep\", [mu, nu],  ordered, kmul, hmul]\n",
    "    '''\n",
    "        Specific Options:\n",
    "        1-  list of the defining partitions\n",
    "        2-  reading order\n",
    "    '''\n",
    "    S = SortedSandpile(G, 0, perm_group, specif_opt)\n",
    "    return S\n",
    "\n",
    "\n",
    "def MultiGeneral_CliqueIndependent_SortedSandpile(cells_graph, card_cell, multi_sink = 1, multiedge_cell = {}, order_cells = []):       ## Specific type of Sandpile\n",
    "    r\"\"\"\n",
    "        Construction of a Sorted Sandpile on the generalized clique-independent graph. Arguments are a graph and a dictionary with values for vertices, such that:\n",
    "            - nodes:    represents a clique or an independent component with |card_cell[node]| vertices.\n",
    "                        If the sign of card_cell[node] is:\n",
    "                            - positive:     we have a clique.\n",
    "                            - negative:     we have an independent.\n",
    "            - edges:    each edge correspond to all possible edges between the two cells connected.\n",
    "        If multiedge_cell is non-empty, each clique will have edges of multeplicity multiedge_cell[node].\n",
    "        If cells_graph has multiple edges, the edges between components will be multiple.\n",
    "    \"\"\"\n",
    "    cell_list = cells_graph.vertices()\n",
    "    \n",
    "    if order_cells == []:\n",
    "        order_cells = copy.copy(cell_list)\n",
    "    \n",
    "    num_vert = sum([abs(card_cell[i]) for i in cell_list])      # Set the total number of vertices for sandpile\n",
    "\n",
    "    dict_cell = {}                                              # Dictionary \"cell -> list vertices\"\n",
    "    index_next_cell = 1\n",
    "    for cell in cell_list:\n",
    "        dict_cell.update({cell:[index_next_cell + j for j in range(abs(card_cell[cell]))]})\n",
    "        index_next_cell += abs(card_cell[cell])\n",
    "    \n",
    "    order = []                                                  # Reading order for qt-Polynomials\n",
    "    for cell in order_cells:                                    \n",
    "        order = order + dict_cell[cell]\n",
    "\n",
    "    edges_set = {0:[i+1 for i in range(num_vert) for k in range(multi_sink)]}   # Set of edges, sink to everyone with multeplicity \"multi_sink\"\n",
    "    perm_group = []                                                             # Set the permutation group\n",
    "\n",
    "    now = 1\n",
    "    index_next_cell = 1\n",
    "    for cell in cell_list:                              # Add the cell\n",
    "        perm_group.append(dict_cell[cell])\n",
    "\n",
    "        for vert in range(abs(card_cell[cell])):\n",
    "            # Add cell with its own vertices\n",
    "            if card_cell[cell] > 0:                         # Add for clique\n",
    "                if cell in multiedge_cell.keys():               # If we have multiple edges...\n",
    "                    next_neigh = [0 for k in range(multi_sink)] + [index_next_cell + j for j in range(abs(card_cell[cell])) for k in range(multiedge_cell[cell]) if index_next_cell + j != now]\n",
    "                else:                                           # If not...\n",
    "                    next_neigh = [0 for k in range(multi_sink)] + [index_next_cell + j for j in range(abs(card_cell[cell])) if index_next_cell + j != now]\n",
    "            else:                                           # Add nothing for independent\n",
    "                next_neigh = [0 for k in range(multi_sink)]\n",
    "            # Add complete with outer edges\n",
    "            for neigh_cell in cells_graph.neighbors(cell):\n",
    "                multi = list(cells_graph.edges(labels=False)).count((cell, neigh_cell))\n",
    "                next_neigh = next_neigh + [x for x in dict_cell[neigh_cell] for k in range(multi)]\n",
    "\n",
    "            # Add to the dictionary\n",
    "            edges_set.update({now:next_neigh})\n",
    "            now += 1\n",
    "\n",
    "        index_next_cell += abs(card_cell[cell])\n",
    "    \n",
    "    # Conversion to sage-math's format\n",
    "    multi_edges_set = {}\n",
    "    for v in range(num_vert + 1):\n",
    "        vertex_dict = {}\n",
    "        for w in set(edges_set[v]):\n",
    "            vertex_dict.update({w:list(edges_set[v]).count(w)})\n",
    "        multi_edges_set.update({v:vertex_dict})\n",
    "    # Construct the graph\n",
    "    G = Graph(edges_set)    #type: ignore\n",
    "    spec_opt = [\"mulgen-clique-indep\", cells_graph, card_cell, order]\n",
    "    '''\n",
    "        Specific Options:\n",
    "        1-  Cell graph\n",
    "        2-  Cell cardinality dictionary\n",
    "        3-  Reading order\n",
    "    '''\n",
    "    S = SortedSandpile(G, 0, perm_group, spec_opt)\n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SandpileSortConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=3\n",
    "S=Multi_CliqueIndependent_SortedSandpile([n],[],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### SageMath implementation of Parking Functions!\n",
    "import copy\n",
    "import sys\n",
    "\n",
    "                                ######################\n",
    "                                #   CLASS PARKFUNC   #\n",
    "                                ######################\n",
    "\n",
    "class ParkFunc():\n",
    "\n",
    "    def __init__(self, n, m, func = [], w_area = [], w_label = [], specific_opt=[], check=False):\n",
    "        r'''\n",
    "            Initialization of the class ParkFunc. The arguments are:\n",
    "            -   n : number of rows of the parking function\n",
    "            -   m : number of columns of the parking function\n",
    "            -   func : a list with the images of values 1,...,n\n",
    "            -   w_area : a list with the direct path information\n",
    "            -   w_label : a list with the direct label information\n",
    "            -   specific_opt : specific options for the parking function\n",
    "            -   check : if True, it check whether the parameters satisfy the condition for being a parking function\n",
    "\n",
    "            When called, it initialize the following data:\n",
    "            -   N : number of rows\n",
    "            -   M : number of columns\n",
    "            -   path : the path shape of the corresponding labelled Dyck path (counting all cells of the NxM grid to the east)\n",
    "            -   label : the labels read from south to north\n",
    "        '''\n",
    "        self.N = n                          # Number of rows\n",
    "        self.M = m                          # Number of columns\n",
    "        self.ratio = n/m                    # Ratio for the diagonal slope\n",
    "\n",
    "        # Recognize the specific parking function type\n",
    "        if specific_opt == []:\n",
    "            if m%n == 0:                # K TYPE\n",
    "                specific_opt = ['k-TYPE', floor(m/n)]   # type: ignore\n",
    "        self.specific_opt = specific_opt    # Specific options for the parking function\n",
    "\n",
    "        # Compute the path and label information\n",
    "        if func != []:\n",
    "            self.label = sorted([i+1 for i in range(self.N)], key = lambda k: k + m*func[k-1])\n",
    "            self.path = [m - func[i-1] + 1 for i in self.label]\n",
    "        else:\n",
    "            self.label = w_label\n",
    "            self.path = w_area\n",
    "\n",
    "        if check:           # Check if the parking condition is satisfied\n",
    "            for i in range(n):\n",
    "                if w_area[i] < ceil(m - self.ratio*i):          # type: ignore\n",
    "                    raise ValueError(\"The path does not satisfy parking function condition...\")\n",
    "    \n",
    "    def __main_diag__(self):\n",
    "        r'''\n",
    "            Returns the main diagonal shape in the right format.\n",
    "        '''\n",
    "        return [ceil(self.M - i/self.ratio) for i in range(self.N)]  # type: ignore\n",
    "\n",
    "    def __eq__(self,other):\n",
    "        r'''\n",
    "            Redefines equality between parking functions not to look at metadata.\n",
    "        '''\n",
    "        if self.path == other.path and self.label == other.label and self.N == other.N and self.M == other.M:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def label_word(self):\n",
    "        return self.label\n",
    "\n",
    "    def area_word(self):\n",
    "        diag = self.__main_diag__()\n",
    "        return [self.path[i] - diag[i] for i in range(self.N)]\n",
    "\n",
    "    def area(self):\n",
    "        r'''\n",
    "            Compute the area statistic.\n",
    "        '''\n",
    "        diag = self.__main_diag__()\n",
    "        return sum([self.path[i] - diag[i] for i in range(self.N)])\n",
    "    \n",
    "    def pdinv(self):                        # PDINV: computes pathdinv statistic\n",
    "        r'''\n",
    "            Compute the path diagonal inversion statistic.\n",
    "        '''\n",
    "        if self.specific_opt[0] != 'k-TYPE':\n",
    "            raise TypeError('The algorithm does not work with this shape...')\n",
    "        k = self.specific_opt[1]\n",
    "        dinv = 0\n",
    "        # Read all cells above path\n",
    "        for i in range(self.N):                  # Loop on rows\n",
    "            for j in range(self.N*k-self.path[i]):       # Loop on columns\n",
    "                arm = (self.N*k - self.path[i]) - (j+1)\n",
    "                leg = i - max([h for h in range(self.N) if self.N*k-self.path[h]-1 < j]) - 1\n",
    "                if (arm <= k*(leg+1)) and (k*leg < arm + 1):\n",
    "                    dinv += 1\n",
    "        return dinv\n",
    "\n",
    "    def tdinv(self):                        # TDINV: computes tdinv statistic\n",
    "        if self.specific_opt[0] != 'k-TYPE':\n",
    "            raise TypeError('The algorithm does not work with this shape...')\n",
    "        k = self.specific_opt[1]\n",
    "\n",
    "        tdinv = 0\n",
    "        row_cresc = [self.label.index(h+1) for h in range(self.N)]\n",
    "        for i in range(self.N):\n",
    "            rank_c = self.N*self.path[row_cresc[i]] + (self.N*k+1)*row_cresc[i]\n",
    "            for j in range(self.N-i-1):\n",
    "                rank_d = self.N*self.path[row_cresc[i+j+1]] + (self.N*k+1)*row_cresc[i+j+1]\n",
    "                if rank_c < rank_d and rank_d < rank_c + (self.N*k):\n",
    "                    tdinv += 1\n",
    "        return tdinv\n",
    "\n",
    "    def w_maxtdinv(self):                   # W_MAXTDINV: computes the labelling giving the max tdinv\n",
    "        if self.specific_opt[0] != 'k-TYPE':\n",
    "            raise TypeError('The algorithm does not work with this shape...')\n",
    "        k = self.specific_opt[1]\n",
    "        \n",
    "        rank_list = [(self.N*k+1)*i + self.N*self.path[i] for i in range(self.N)]\n",
    "        order = sorted(range(len(rank_list)), key=lambda k: rank_list[k])\n",
    "        park = sorted(range(len(order)), key=lambda k: order[k])\n",
    "        return [i+1 for i in park]\n",
    "\n",
    "    def maxtdinv(self):                     # MAXTDINV: computes maxtdinv statistic\n",
    "        max_pf = ParkFunc(self.N, self.M, w_area=self.path, w_label=self.w_maxtdinv(), specific_opt=self.specific_opt)\n",
    "        return max_pf.tdinv()\n",
    "\n",
    "    def dinv(self):                         # DINV: computes the dinv of a parking function\n",
    "        #print(\"PDINV: {}\\t TDINV: {}\\t MAXTDINV: {}\".format(self.pdinv(),self.tdinv(),self.maxtdinv()))\n",
    "        return self.pdinv() + self.tdinv() - self.maxtdinv()\n",
    "\n",
    "    def pmaj(self, infos=False):            # PMAJ: computes the pmak of a parking function\n",
    "        if self.specific_opt[0] != 'k-TYPE':\n",
    "            raise TypeError('The algorithm does not work with this shape...')\n",
    "        k = self.specific_opt[1]\n",
    "        \n",
    "        pmaj = 0\n",
    "        plus = 0\n",
    "        current = self.N+1\n",
    "        reading_word = []\n",
    "        contributes = []\n",
    "        buffer = []\n",
    "        for i in range(self.N*k):\n",
    "            # Adding to buffer new labels with k multeplicity\n",
    "            new = [self.label[j] for j in range(self.N) if self.path[j] == self.N*k-i]\n",
    "            buffer = buffer + [new[floor(j/k)] for j in range(len(new)*k)]  # type: ignore\n",
    "            # Get next step\n",
    "            if current <= min(buffer):          # Starting new ascending chain\n",
    "                plus += 1\n",
    "                current = max(buffer)\n",
    "            else:                               # Continuing current ascending chain\n",
    "                current = max([w for w in buffer if w < current])\n",
    "            \n",
    "            if current not in reading_word:     # Adding pmaj if needed...\n",
    "                pmaj += plus\n",
    "                contributes = contributes + [[current,plus]]\n",
    "            buffer.remove(current)                 # Removing one copy of current from buffer\n",
    "\n",
    "            # writing down the new letter in reading word\n",
    "            reading_word = reading_word + [current]\n",
    "        if infos:\n",
    "            return [pmaj,contributes,reading_word]\n",
    "        else:\n",
    "            return pmaj\n",
    "\n",
    "    def path_word(self):\n",
    "        if self.specific_opt[0] != 'k-TYPE':\n",
    "            raise TypeError('The algorithm does not work with this shape...')\n",
    "        k = self.specific_opt[1]\n",
    "        \n",
    "        rank_list = [(self.N*k+1)*i + self.N*self.path[i] for i in range(self.N)]\n",
    "        path_order = sorted(range(len(rank_list)), key=lambda k: rank_list[k])      # Reading order of the columns\n",
    "        path_word = [self.label[path_order[i]] for i in range(self.N)]\n",
    "        return path_word\n",
    "\n",
    "    def to_area_pmaj(self,infos = False):   # TO_AREA_PMAJ: this is the Generalized Loehr-Remmel map\n",
    "        r'''\n",
    "            This function returns the image of the parking function through the generalized Loehr-Remmel map.\n",
    "        '''\n",
    "        if self.specific_opt[0] != 'k-TYPE':\n",
    "            raise TypeError('The algorithm does not work with this shape...')\n",
    "        k = self.specific_opt[1]\n",
    "        \n",
    "        ### Create the path word, ordered by rank\n",
    "        rank_list = [(self.N*k+1)*i + self.N*self.path[i] for i in range(self.N)]\n",
    "        path_order = sorted(range(len(rank_list)), key=lambda k: rank_list[k])      # Reading order of the columns\n",
    "        path_word = [self.label[path_order[i]] for i in range(self.N)]                      # Labels in order\n",
    "        #print(\"The path_word: {}\".format(path_word))\n",
    "\n",
    "        ### Compute the not_tdinv\n",
    "        # Compute all pairs of cars making tdinv\n",
    "        tdinv_pairs = []            \n",
    "        row_cresc = [self.label.index(h+1) for h in range(self.N)]\n",
    "        for i in range(self.N):\n",
    "            rank_c = self.N*self.path[row_cresc[i]] + (self.N*k+1)*row_cresc[i]\n",
    "            for j in range(self.N-i-1):\n",
    "                rank_d = self.N*self.path[row_cresc[i+j+1]] + (self.N*k+1)*row_cresc[i+j+1]\n",
    "                if rank_c < rank_d and rank_d < rank_c + (self.N*k+1):\n",
    "                    tdinv_pairs = tdinv_pairs + [(i+1,i+j+2)]\n",
    "\n",
    "        # Compute not_tdinv with previous cars\n",
    "        not_tdinv = []\n",
    "        for i in range(self.N):\n",
    "            temp = 0\n",
    "            for j in range(i):\n",
    "                if ((path_word[i],path_word[j]) not in tdinv_pairs) and ((path_word[j],path_word[i]) not in tdinv_pairs):\n",
    "                    temp += 1\n",
    "            not_tdinv = not_tdinv + [temp]\n",
    "        #print(\"The not_tdinv: {}\".format(not_tdinv))\n",
    "\n",
    "        ### Compute the not_dinvcorr\n",
    "        # Compute all pairs of cars making dinvcorr\n",
    "        dinvcorr_pairs = []\n",
    "        for i in range(self.N):\n",
    "            rank_c = self.N*self.path[i] + (self.N*k+1)*i\n",
    "            for j in range(self.N-i-1):\n",
    "                rank_d = self.N*self.path[i+j+1] + (self.N*k+1)*(i+j+1)\n",
    "                for shift in range(k-1):\n",
    "                    if rank_d < rank_c + self.N*(k-1) - self.N*shift and rank_c - self.N - self.N*shift < rank_d:\n",
    "                        dinvcorr_pairs = dinvcorr_pairs + [(self.label[i],self.label[i+j+1])]\n",
    "        # Compute not_dinvcorr with previous cars\n",
    "        not_dinvcorr = []\n",
    "        for i in range(self.N):\n",
    "            temp = 0\n",
    "            for j in range(i):\n",
    "                temp += k - 1 - len([1 for (a,b) in dinvcorr_pairs if (a,b)==(path_word[i],path_word[j]) or (a,b)==(path_word[j],path_word[i])])\n",
    "            not_dinvcorr = not_dinvcorr + [temp]\n",
    "\n",
    "        ### Compute the not_dinv\n",
    "        not_dinv = [not_tdinv[i] + not_dinvcorr[i] for i in range(self.N)]\n",
    "        #print(\"The not_dinv: {}\".format(not_dinv))\n",
    "\n",
    "        ### Compute the w_path of the image\n",
    "        not_dinv_sort = sorted(not_dinv, key=lambda k: k)\n",
    "        area_word = [self.N*k-not_dinv_sort[i] for i in range(self.N)]\n",
    "        \n",
    "        ### Compute the w_label of the image\n",
    "        label_word = [path_word[i] for i in sorted(range(self.N), key=lambda k: not_dinv[k]*self.N + path_word[k])]\n",
    "        if not infos:\n",
    "            return ParkFunc(self.N, self.M, w_area=area_word, w_label=label_word, specific_opt=self.specific_opt)\n",
    "        else:\n",
    "            return [ParkFunc(self.N, self.M, w_area=area_word, w_label=label_word, specific_opt=self.specific_opt), not_tdinv, not_dinvcorr]\n",
    "\n",
    "    def to_dinv_area(self,infos = False):   # TO_DINV_AREA: this is the Generalized Loehr-Remmel inverse\n",
    "        r'''\n",
    "            This function returns the image through the generalized Loehr-Remmel inverse.\n",
    "        '''\n",
    "        if self.specific_opt[0] != 'k-TYPE':\n",
    "            raise TypeError('The algorithm does not work with this shape...')\n",
    "        k = self.specific_opt[1]\n",
    "\n",
    "        #self.draw()\n",
    "\n",
    "        ### Compute the pmaj contributes of each label\n",
    "        [pmaj, contributes, reading_word] = self.pmaj(infos = True)\n",
    "        lab_ord = [v[0] for v in contributes]       # Ordered list of the inserted labels\n",
    "        area = [v[1] for v in contributes]          # Ordered list of final area contributes of each label\n",
    "        #print(\"Label order {}\".format(lab_ord))\n",
    "        #print(\"Area {}\".format(area))\n",
    "        ### Compute the area contributes of each label\n",
    "        #print(\"Path {}\".format(self.path))\n",
    "        codinv_dict = {self.label[i]:(self.M - self.path[i]) for i in range(self.N)}\n",
    "        dinv = [k*i - codinv_dict[lab_ord[i]] for i in range(self.N)]\n",
    "        #print(\"Dinv {}\".format(dinv))\n",
    "\n",
    "        ### Build up the path step by step\n",
    "        # First step\n",
    "        m = 1\n",
    "        label = [lab_ord[0]]\n",
    "        path = [k]\n",
    "        # Consecutive steps\n",
    "        for j in range(self.N-1):\n",
    "            if infos:\n",
    "                print(\"\\nDIMENSION {} PARTIAL PATH {} PARTIAL LABEL {}\".format(j,path,label))\n",
    "            j += 1\n",
    "            check = False\n",
    "            #print([(m-(pos+1))*k + area[j] for pos in range(m-1)])\n",
    "            #tries = [pos+1 for pos in range(m-1) if ((m+1)*k >= ((m+1)-(pos+1))*k + area[j]) and (path[pos]+k >= ((m+1)-(pos+1))*k + area[j]) and (path[pos+1] <= ((m+1)-(pos+1))*k + area[j])] + [m]\n",
    "            tries = [pos+1 for pos in range(m-1) if ((pos+1)*k >= area[j]) and (path[pos]+k >= (m-pos)*k + area[j]) and (path[pos+1] <= (m-pos)*k + area[j])] + [m]\n",
    "            if area[j] == 0:\n",
    "                tries = [0] + tries\n",
    "            ind = 0\n",
    "            if infos:\n",
    "                print(\"POSITIONS TO TRY {}\".format(tries))\n",
    "            while ind < len(tries) and check == False:\n",
    "                temp_path1 = [path[i]+k for i in range(tries[ind])]                     # Before new step\n",
    "                temp_path3 = [path[tries[ind]+i] for i in range(m-tries[ind])]        # After new step\n",
    "                #print([tries[ind]+i for i in range(m-tries[ind])])        # After new step\n",
    "                temp_path = temp_path1 + [(m+1-tries[ind])*k + area[j]] + temp_path3    # Provisional path\n",
    "                \n",
    "                temp_label1 = [label[i] for i in range(tries[ind])]                     # Before new label\n",
    "                temp_label3 = [label[tries[ind]+i] for i in range(m-tries[ind])]      # After new label\n",
    "                temp_label = temp_label1 + [lab_ord[j]] + temp_label3                   # Provisional label\n",
    "                order = sorted(range(m+1), key = lambda i: temp_label[i])\n",
    "                norm_label = sorted(range(m+1), key = lambda i: order[i])\n",
    "                norm_label = [v+1 for v in norm_label]                                  # Normalized label\n",
    "                #print(\"Temp {} \\t Norm {}\".format(temp_label,norm_label))\n",
    "                if infos:\n",
    "                    print(\"First part {}\".format(temp_path1))\n",
    "                    print(\"Second part {}\".format((m+1-tries[ind])*k + area[j]))\n",
    "                    print(\"Third part {}\".format(temp_path3))\n",
    "                #print(\"Trying label {}\\t and path {}\".format(norm_label,temp_path))\n",
    "                temp = ParkFunc(m+1,k*(m+1), w_area=temp_path,w_label=norm_label)\n",
    "                if infos:\n",
    "                    temp.draw()\n",
    "                dinv_val = temp.dinv()\n",
    "                if sum([dinv[i] for i in range(m+1)]) == dinv_val:\n",
    "                    #print(\"\\tGOOD: We have dinv {}\\t with dinv_val {}\\t and sum {}\".format(dinv, dinv_val,sum([dinv[i] for i in range(m+1)])))\n",
    "                    label = temp_label\n",
    "                    path = temp_path\n",
    "                    check = True\n",
    "                #else:\n",
    "                    #print(\"\\tBAD: We have dinv {}\\t with dinv_val {}\\t and sum {}\".format(dinv, dinv_val,sum([dinv[i] for i in range(m+1)])))\n",
    "                ind += 1\n",
    "            \n",
    "            if check == False:\n",
    "                print(\"First part {}\".format(temp_path1))\n",
    "                print(\"Second part {}\".format((m+1-tries[ind-1])*k + area[j]))\n",
    "                print(\"Third part {}\".format(temp_path3))\n",
    "                raise ValueError(\"PROBLEMO!\")\n",
    "            m+=1\n",
    "        \n",
    "        return ParkFunc(self.N, self.M, w_area=path, w_label=label)\n",
    "\n",
    "\n",
    "                                ##########################\n",
    "                                #   PARKFUNC UTILITIES   #\n",
    "                                ##########################\n",
    "\n",
    "    def draw(self, stats=True):\n",
    "        r'''\n",
    "            Function that draws the path\n",
    "        '''\n",
    "        #print('Path {} and {}'.format(self.path,self.M))\n",
    "        diag = self.__main_diag__()\n",
    "        for i in range(self.N):\n",
    "            i = self.N - i - 1\n",
    "            row1 = '   ' * (self.M - self.path[i])\n",
    "            row2 = ' {:>2}'.format(self.label[i])\n",
    "            row3 = '|##' * (self.path[i] - diag[i])\n",
    "            row4 = '|  ' * (diag[i]) + '|'\n",
    "\n",
    "            buff1 = '   ' * (self.M - self.path[i]+1)\n",
    "            buff2 = '+--' * (self.path[i]) + '+'\n",
    "            print('\\t' + buff1 + buff2)\n",
    "            print('\\t' + row1 + row2 + row3 + row4)\n",
    "        print('\\t' + '   ' + '+--' * self.M + '+')\n",
    "        if stats:\n",
    "            print(\" Label word:\\t{}\".format(self.label_word()))\n",
    "            print(\" Area word:\\t{}\".format(self.area_word()))\n",
    "            print(\" Area: {}\\t Dinv: {}\\t Pmaj: {}\".format(self.area(),self.dinv(),self.pmaj()))\n",
    "\n",
    "def kDyckPaths(n,k):                            # kDYCKPATHS: computes the set of all (nk,n)-Dyck paths\n",
    "    possible_paths = [[1]]\n",
    "    for i in range(n*(k+1)-1):\n",
    "        new_possible = []\n",
    "        for part_path in possible_paths:\n",
    "            height = sum(part_path)\n",
    "            distance = sum([1-part_path[j] for j in range(i+1)])\n",
    "            if height == n:                 # Reached max height, just 0's\n",
    "                temp = copy.deepcopy(part_path)\n",
    "                temp.append(0)\n",
    "                new_possible.append(temp)\n",
    "            elif k*height < distance + 1:   # Reached the \"diagonal\", just a 1\n",
    "                temp = copy.deepcopy(part_path)\n",
    "                temp.append(1)\n",
    "                new_possible.append(temp)\n",
    "            else:\n",
    "                temp = copy.deepcopy(part_path)\n",
    "                temp.append(0)\n",
    "                new_possible.append(temp)\n",
    "                temp = copy.deepcopy(part_path)\n",
    "                temp.append(1)\n",
    "                new_possible.append(temp)\n",
    "        possible_paths = new_possible\n",
    "    dyck_k_paths = [[sum([1-w[i+j] for j in range(len(w)-i)]) for i in range(len(w)) if w[i]==1] for w in possible_paths]\n",
    "    return dyck_k_paths\n",
    "\n",
    "def nkParkingFunctions(n,k, display=False):     # kPARKINGFUNCTIONS: computes the set of all (n,k)-parking functions\n",
    "    parking_functions = []\n",
    "    counter = 0\n",
    "    # Compute total number of Dyck paths\n",
    "    totalnum = binomial(n*(k+1)+1, n)/(n*(k+1)+1)           # type: ignore\n",
    "    print(\"Starting the algorithm to compute all parking functions...\")\n",
    "    # Compute all possible set partitions\n",
    "    set_partitions = {}\n",
    "    for lamb in Partitions(n):                              # type: ignore\n",
    "        temp = []\n",
    "        for possible in OrderedSetPartitions(n,Composition(lamb)):       # type: ignore\n",
    "            poss = [list(part) for part in possible]\n",
    "            temp.append(poss)\n",
    "        lambt = tuple(lamb)\n",
    "        set_partitions.update({lambt:temp})\n",
    "\n",
    "    ### Loop on k-Dyck paths\n",
    "    for path in kDyckPaths(n,k):\n",
    "        if display:\n",
    "            counter += 1\n",
    "            perc = floor(100*counter/totalnum)              # type: ignore\n",
    "            sys.stdout.write('\\r')                          # Reset to start of line\n",
    "            sys.stdout.write(\"Percentage %3d %%, computing parking functions for path %6d of %6d\" % (perc, counter, totalnum))\n",
    "            sys.stdout.flush()\n",
    "\n",
    "        # Compute the partitions we want\n",
    "        rec_partition = [len([1 for w in path if w==n*k-i]) for i in range(n*k) if (n*k-i) in path]\n",
    "        #print(rec_partition)\n",
    "        ord_partition = copy.copy(rec_partition)\n",
    "        ord_partition.sort()\n",
    "        ord_partition.reverse()\n",
    "        #print(ord_partition)\n",
    "        ord_partitiont = tuple(ord_partition)\n",
    "        #print(ord_partitiont)\n",
    "        part_decr_ord = sorted(range(len(rec_partition)), key=lambda i: -n*rec_partition[i])\n",
    "        read_order = sorted(range(len(part_decr_ord)), key=lambda i: part_decr_ord[i])\n",
    "        for set_part in set_partitions[ord_partitiont]:\n",
    "            label = []\n",
    "            for j in read_order:\n",
    "                temp2 = list(list(set_part)[j])\n",
    "                temp2.sort()\n",
    "                label = label + temp2\n",
    "            parking_functions.append(ParkFunc(n,n*k,w_area=path,w_label=label))\n",
    "    \n",
    "    print(\"\\n...the algorithm to compute all parking functions has finished.\")\n",
    "    return parking_functions\n",
    "\n",
    "def qt_Polynomial_dinv_area(set_paths,ring):           # GEN_POLY: polynomial generated by paths\n",
    "    q = ring.gens()[0]\n",
    "    t = ring.gens()[1]\n",
    "    poly = 0*q*t\n",
    "    for path in set_paths:\n",
    "        poly = poly + (q**path.dinv())*(t**path.area())\n",
    "    return poly\n",
    "\n",
    "def qt_Polynomial_area_pmaj(set_paths,ring):           # GEN_POLY: polynomial generated by paths\n",
    "    q = ring.gens()[0]\n",
    "    t = ring.gens()[1]\n",
    "    poly = 0*q*t\n",
    "    for path in set_paths:\n",
    "        poly = poly + (q**path.area())*(t**path.pmaj())\n",
    "    return poly\n",
    "\n",
    "def menk(aa,k): #remove k from each element of a list\n",
    "    return [a-k for a in aa]\n",
    "\n",
    "def piuk(aa,k): #add k to each element of a list\n",
    "    return [a+k for a in aa]\n",
    "\n",
    "from itertools import product\n",
    "from numpy import argmin\n",
    "\n",
    "def easy_bounce(path): #calculate bounce stat for Dyck Paths ([1,1,-1,1,-1,-1]) from 0,0 to n,n\n",
    "    pp=deepcopy(path)\n",
    "    n=len(pp)\n",
    "    gg=[sum(pp[:i]) for i in range(n)]\n",
    "    c=-min(gg)\n",
    "    j=argmin(gg)\n",
    "    start=0\n",
    "    pos=start\n",
    "    bounce=[]\n",
    "    i=0\n",
    "    bb=0\n",
    "    bs=[]\n",
    "    i=0\n",
    "    while i<n:\n",
    "        if sum(bounce[:i])==0:\n",
    "            bounce.append(1)\n",
    "        else:\n",
    "            if bounce[-1]==-1:\n",
    "                bounce.append(-1)\n",
    "            else:\n",
    "                if sum(bounce[:i])==sum(pp[:i]):\n",
    "                    if pp[i]==-1:\n",
    "                        bb+=1\n",
    "                    bounce.append(pp[i])\n",
    "                else:\n",
    "                    bounce.append(1)\n",
    "        bs.append(bb)\n",
    "        i+=1\n",
    "    return sum([bs[i] for i in range(n) if pp[i]==1])\n",
    "\n",
    "def path_ord(p1,p2): #It is true if path p1 is above path p2 (paths with 1 and -1)\n",
    "    n=len(p1)\n",
    "    g1=[sum(p1[:i]) for i in range(n)]\n",
    "    g2=[sum(p2[:i]) for i in range(n)]\n",
    "    x=True\n",
    "    i=0\n",
    "    while x and i<n:\n",
    "        if g1[i]<g2[i]:\n",
    "            x=False\n",
    "        i+=1\n",
    "    return x\n",
    "\n",
    "def my_Paths(n): #list of all paths from 0,0 to n,n (with 1 and -1)\n",
    "    return [list(seq) for seq in product([-1, 1], repeat=2*n) if sum(seq) == 0]\n",
    "\n",
    "def my_DyckPaths(n): #list of all Dyck paths from 0,0 to n,n (with 1 and -1)\n",
    "    dd=[(-1)**i for i in range(2*n)]\n",
    "    return [pp for pp in my_Paths(n) if path_ord(pp,dd)]\n",
    "\n",
    "def from_my_to_area(pp): #convert a path with 1 and -1 in its complete! area word\n",
    "    aa=list(pp)\n",
    "    n=len(aa)/2\n",
    "    return [[sum(aa[:i]) for i in range(2*n) if aa[i]==1][j]+n-j for j in range(n)]\n",
    "\n",
    "def from_area_to_my(pp): #convert a completh area word in a path with 1 and -1\n",
    "    n=len(pp)\n",
    "    bb=list(pp)+[0]\n",
    "    x=[]\n",
    "    for i in range(n):\n",
    "        x=x+[1]+[-1 for a in range(bb[i]-bb[i+1])]\n",
    "    return x\n",
    "\n",
    "def sc_bo(n,k,dizi=[],perc=[],start=0): \n",
    "    #return a list of dictionaries, such that the i-th ([i-1]...) is the list of all paths in n,k*n rectangular\n",
    "    #above the diagonal, with the bounce decomposition statistic\n",
    "    if start==0:\n",
    "        dizi=[{} for a in range(k+1)]    \n",
    "        dizi[1].update({tuple(menk(from_my_to_area(a),1)):easy_bounce(a) for a in my_DyckPaths(n)})\n",
    "        perc=[{}]+[{tuple(menk(a,i)):1 for a in kDyckPaths(n,i)} for i in range(1,k+1)]\n",
    "    if len(dizi[k])>0:\n",
    "        return [dizi[j] for j in range(1,k+1)]\n",
    "    km1=sc_bo(n,k-1,dizi,perc,1)[-1]\n",
    "    for aa in km1:\n",
    "        for bb in dizi[1]:\n",
    "            cc=[list(aa)[i]+list(bb)[i] for i in range(n)]\n",
    "            if tuple(cc) in perc[k]:\n",
    "                new=easy_bounce(from_area_to_my(list(bb)))+dizi[k-1][aa]\n",
    "                if tuple(cc) in dizi[k]:\n",
    "                    if dizi[k][tuple(cc)]>new:\n",
    "                        dizi[k][tuple(cc)]=new\n",
    "                else:\n",
    "                    dizi[k].update({tuple(cc):new})\n",
    "    return [dizi[j] for j in range(1,k+1)]\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "n=3\n",
    "k=3\n",
    "#3,12  4,8   5,8  6,5\n",
    "diz=sc_bo(n,k)\n",
    "print(diz)\n",
    "for bb in diz[-1]:#check if the bounce decomposition statistic is the same of the new pmaj\n",
    "    if diz[-1][bb]!=ParkFunc(n,n*k,w_area=piuk(bb,k),w_label=list(range(1,n+1))).pmaj():\n",
    "        print(bb)\n",
    "print('ciao')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for aa in kDyckPaths(n,k):\n",
    "    print(menk(aa,k))\n",
    "    print(ParkFunc(n,n*k,w_area=aa,w_label=list(range(1,n+1))).pmaj())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SageMath 10.4.beta7",
   "language": "sage",
   "name": "sagemath-dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "sage",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
